#
# Ci-dessous la config qui permet de lancer convergence-bacon-docker
#
# Remarque: avant de lancer docker-compose up, il faut régler le fichier .env
# en partant du fichier .env-dist qui donne les variables d'environnements
# à personnaliser et des exemples de valeurs.
#

version: "3.7"
services:
  ############################
  # kbart2kafka-api
  # API de kbart2kafka-api
  # (écrite en java spring boot)
  kbart2kafka-api:
    image: abesesr/convergence:${KBART2KAFKA_API_VERSION}
    container_name: kbart2kafka-api
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    environment:
      # Pour basculer sur bon application-xxx.properties préalablement embarqué
      # dans le code ici:
      # https://github.com/abes-esr/abes-hello-back/tree/develop/web/src/main/resources/
      SPRING_PROFILES_ACTIVE: ${KBART2KAFKA_API_SPRING_PROFILES_ACTIVE}
      # Pour surcharger les paramètres spring du application-xxx.properties
      # ci-dessous via le système de .env de docker
      # https://www.linkedin.com/pulse/externalizing-properties-spring-boot-application-docker-phani-bushan
      # pour la liste de tous les champs qu'on peut surcharger,
      # voir le contenu des application-xxx.properties embarqués dans le code sources
      SPRING_KAFKA_PRODUCER_BOOTSTRAP_SERVERS: ${KBART2KAFKA_API_SPRING_KAFKA_PRODUCER_BOOTSTRAP_SERVERS}
      SPRING_DATASOURCE_BASEXML_JDBCURL: ${KBART2KAFKA_API_SPRING_DATASOURCE_BASEXML_JDBCURL}
      SPRING_DATASOURCE_BASEXML_USERNAME: ${KBART2KAFKA_API_SPRING_DATASOURCE_BASEXML_USERNAME}
      SPRING_DATASOURCE_BASEXML_PASSWORD: ${KBART2KAFKA_API_SPRING_DATASOURCE_BASEXML_PASSWORD}
      URL_ONLINEID2PPN: ${KBART2KAFKA_API_URL_ONLINEID2PPN}
      URL_PRINTID2PPN: ${KBART2KAFKA_API_URL_PRINTID2PPN}
      URL_DAT2PPN: ${KBART2KAFKA_API_URL_DAT2PPN}
      MAIL_WS_URL: ${KBART2KAFKA_API_MAIL_WS_URL}
      MAIL_WS_RECIPIENT: ${KBART2KAFKA_API_MAIL_WS_RECIPIENT}

    ports:
      - ${KBART2KAFKA_API_HTTP_PORT}:8082
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=kbart2kafka"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=java-spring"
      # pour que les mises à jour de cette image soient auto-déployées par watchtower
      - "com.centurylinklabs.watchtower.scope=kbart2kafka-watchtower-scope"

  #######################################
  # kbart2kafka-api-watchtower
  # Conteneur chargé de mettre à jour automatiquement toutes les N secondes
  # les images docker des conteneurs surveillés (via le système de label/scope de watchtower)
  # plus d'info : https://containrrr.dev/watchtower
  # cf README.md pour explications : https://github.com/abes-esr/qualimarc-docker#d%C3%A9ploiement-continu
  kbart2kafka-api-watchtower:
    image: containrrr/watchtower:1.4.0
    container_name: kbart2kafka-api-watchtower
    restart: unless-stopped
    mem_limit: 2g
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      WATCHTOWER_CLEANUP: "true"
      WATCHTOWER_POLL_INTERVAL: 60
      WATCHTOWER_DEBUG: "false"
      WATCHTOWER_NO_STARTUP_MESSAGE: "true"
      WATCHTOWER_WARN_ON_HEAD_FAILURE: "never"
      WATCHTOWER_RUN_ONCE: ${CONVERGENCE_BACON_API_WATCHTOWER_RUN_ONCE}
      WATCHTOWER_NOTIFICATIONS: "slack"
      WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL: ${CONVERGENCE_BACON_API_WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL}
      WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER: ${KBART2KAFKA_API_WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER}
      WATCHTOWER_NOTIFICATION_SLACK_CHANNEL: "#notif-convergence"
      WATCHTOWER_SCOPE: "kbart2kafka-watchtower-scope"
    labels:
      - "com.centurylinklabs.watchtower.scope=kbart2kafka-watchtower-scope"

  ############################
  # kbart2kafka-api
  # API de kbart2kafka-api
  # (écrite en java spring boot)
  logskbart-api:
    image: abesesr/convergence:${LOGSKBART_API_VERSION}
    container_name: logskbart-api
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    volumes:
      - ${LOGSKBART_API_WORKDIR}:/tmp/
    environment:
      # Pour basculer sur bon application-xxx.properties préalablement embarqué
      # dans le code ici:
      # https://github.com/abes-esr/abes-hello-back/tree/develop/web/src/main/resources/
      SPRING_PROFILES_ACTIVE: ${KBART2KAFKA_API_SPRING_PROFILES_ACTIVE}
      # Pour surcharger les paramètres spring du application-xxx.properties
      # ci-dessous via le système de .env de docker
      # https://www.linkedin.com/pulse/externalizing-properties-spring-boot-application-docker-phani-bushan
      # pour la liste de tous les champs qu'on peut surcharger,
      # voir le contenu des application-xxx.properties embarqués dans le code sources
      SPRING_KAFKA_CONSUMER_BOOTSTRAP_SERVERS: ${LOGSKBART_API_SPRING_KAFKA_CONSUMER_BOOTSTRAP_SERVERS}
      SPRING_DATASOURCE_URL: ${LOGSKBART_API_SPRING_DATASOURCE_URL}
      SPRING_DATASOURCE_USERNAME: ${LOGSKBART_API_SPRING_DATASOURCE_USERNAME}
      SPRING_DATASOURCE_PASSWORD: ${LOGSKBART_API_SPRING_DATASOURCE_PASSWORD}
      PATH_TSVFILE: ${LOGSKBART_API_PATH_TSVFILE}
      LOADERTYPE: ${LOGSKBART_API_LOADERTYPE}
    ports:
      - ${LOGSKBART_API_HTTP_PORT}:8082
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=logskbart"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=java-spring"
      # pour que les mises à jour de cette image soient auto-déployées par watchtower
      - "com.centurylinklabs.watchtower.scope=logskbart-watchtower-scope"


  #######################################
  # logskbart-api-watchtower
  # Conteneur chargé de mettre à jour automatiquement toutes les N secondes
  # les images docker des conteneurs surveillés (via le système de label/scope de watchtower)
  # plus d'info : https://containrrr.dev/watchtower
  # cf README.md pour explications : https://github.com/abes-esr/qualimarc-docker#d%C3%A9ploiement-continu
  logskbart-api-watchtower:
    image: containrrr/watchtower:1.4.0
    container_name: logskbart-api-watchtower
    restart: unless-stopped
    mem_limit: 2g
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      WATCHTOWER_CLEANUP: "true"
      WATCHTOWER_POLL_INTERVAL: 60
      WATCHTOWER_DEBUG: "false"
      WATCHTOWER_NO_STARTUP_MESSAGE: "true"
      WATCHTOWER_WARN_ON_HEAD_FAILURE: "never"
      WATCHTOWER_RUN_ONCE: ${CONVERGENCE_BACON_API_WATCHTOWER_RUN_ONCE}
      WATCHTOWER_NOTIFICATIONS: "slack"
      WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL: ${CONVERGENCE_BACON_API_WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL}
      WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER: ${LOGSKBART_API_WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER}
      WATCHTOWER_NOTIFICATION_SLACK_CHANNEL: "#notif-convergence"
      WATCHTOWER_SCOPE: "logskbart-watchtower-scope"
    labels:
      - "com.centurylinklabs.watchtower.scope=logskbart-watchtower-scope"

  ##############################
  # logskbart-db
  # Base de données postgresql de logskbart
  logskbart-db:
    image: abesesr/postgres-fr_fr:15.1.0
    container_name: logskbart-db
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    environment:
      # cf https://github.com/docker-library/docs/blob/master/postgres/README.md#environment-variables
      POSTGRES_DB: "logskbart"
      POSTGRES_USER: ${LOGSKBART_DB_POSTGRES_USER}
      POSTGRES_PASSWORD: ${LOGSKBART_DB_POSTGRES_PASSWORD}
    volumes:
      - ./volumes/logskbart-db/pgdata/:/var/lib/postgresql/data/
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=qualimarc"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=postgresql"



  #################################
  # logskbart-db-adminer
  # Interface d'admin de postgresql
  logskbart-db-adminer:
    image: adminer:4.8.1
    container_name: logskbart-db-adminer
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    ports:
      - ${LOGSKBART_DB_ADMINER_HTTP_PORT}:8080
    depends_on:
      - logskbart-db
    environment:
      ADMINER_DEFAULT_SERVER: "logskbart-db"
    logging:
      driver: none # pas de log pour adminer pour ne pas polluer



  #######################################
  # logskbart-db-dumper
  # Dump de la base de données postgresql
  # (dump tous les jours pour les sauvegardes)
  # https://github.com/tiredofit/docker-db-backup
  logskbart-db-dumper:
    image: tiredofit/db-backup:3.3.11
    container_name: logskbart-db-dumper
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    volumes:
      - ./volumes/logskbart-db/dump/:/backup/
    depends_on:
      - logskbart-db
    environment:
      # DB_DUMP_BEGIN: "0130" <= tous les jours à 1h30 du matin GMT
      # DB_DUMP_FREQ: 1440 <= chaque jour
      # DB_CLEANUP_TIME: 10080 (1440*7) <= conserve uniquement les 7 derniers jours
      DB_TYPE: "pgsql"
      DB_HOST: "logskbart-db"
      DB_NAME: "logskbart"
      DB_USER: ${LOGSKBART_DB_POSTGRES_USER}
      DB_PASS: ${LOGSKBART_DB_POSTGRES_PASSWORD}
      DB_DUMP_BEGIN: "0130"
      DB_DUMP_FREQ: 1440
      DB_CLEANUP_TIME: 10080
      SPLIT_DB: "true"
      COMPRESSION: "GZ"
      DEBUG_MODE: "false"
      CONTAINER_ENABLE_SCHEDULING: "false"
      CONTAINER_ENABLE_MONITORING: "false"
    labels:
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=logskbart"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=adhoc"
      # log multiline aussi pour ce conteneur avec des lignes qui ressemblent à ceci:
      # 2022-08-01.14:55:00 [NOTICE] ** [db-backup] Dumping PostgresSQL database: 'logskbart' and compressing with 'gzip'
      - "co.elastic.logs/multiline.type=pattern"
      - "co.elastic.logs/multiline.pattern='^.*Dumping PostgresSQL database'"
      - "co.elastic.logs/multiline.negate=true"
      - "co.elastic.logs/multiline.match=after"
