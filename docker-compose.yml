#
# Ci-dessous la config qui permet de lancer convergence-bacon-docker
#
# Remarque: avant de lancer docker-compose up, il faut régler le fichier .env
# en partant du fichier .env-dist qui donne les variables d'environnements
# à personnaliser et des exemples de valeurs.
#

version: "3.7"
services:
  ############################
  # kbart2kafka
  # (écrite en java spring boot)
  kbart2kafka:
    image: abesesr/convergence:${KBART2KAFKA_VERSION}
    container_name: kbart2kafka
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    command: tail -F /dev/null
    volumes:
      - ./volumes/kbart2kafka/:/app/kbart/
    environment:
      # Pour basculer sur bon application-xxx.properties préalablement embarqué
      # dans le code ici:
      # https://github.com/abes-esr/abes-hello-back/tree/develop/web/src/main/resources/
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE}
      # Pour surcharger les paramètres spring du application-xxx.properties
      # ci-dessous via le système de .env de docker
      # https://www.linkedin.com/pulse/externalizing-properties-spring-boot-application-docker-phani-bushan
      # pour la liste de tous les champs qu'on peut surcharger,
      # voir le contenu des application-xxx.properties embarqués dans le code sources
      SPRING_KAFKA_PRODUCER_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      SPRING_DATASOURCE_BASEXML_JDBCURL: ${KBART2KAFKA_SPRING_DATASOURCE_BASEXML_JDBCURL}
      SPRING_DATASOURCE_BASEXML_USERNAME: ${KBART2KAFKA_SPRING_DATASOURCE_BASEXML_USERNAME}
      SPRING_DATASOURCE_BASEXML_PASSWORD: ${KBART2KAFKA_SPRING_DATASOURCE_BASEXML_PASSWORD}
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=kbart2kafka"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=java-spring"
      # pour que les mises à jour de cette image soient auto-déployées par watchtower
      - "com.centurylinklabs.watchtower.scope=convergence-bacon-watchtower-scope"

  #########################################
  # best-ppn-api
  # API en spring
  best-ppn-api:
    image: abesesr/convergence:${BESTPPNAPI_VERSION}
    container_name: best-ppn-api
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    ports:
      - ${BESTPPNAPI_PORT}:8083
    environment:
      # Pour basculer sur bon application-xxx.properties préalablement embarqué
      # dans le code ici:
      # https://github.com/abes-esr/abes-hello-back/tree/develop/web/src/main/resources/
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE}
      # Pour surcharger les paramètres spring du application-xxx.properties
      # ci-dessous via le système de .env de docker
      # https://www.linkedin.com/pulse/externalizing-properties-spring-boot-application-docker-phani-bushan
      # pour la liste de tous les champs qu'on peut surcharger,
      # voir le contenu des application-xxx.properties embarqués dans le code sources
      SPRING_KAFKA_PRODUCER_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      SPRING_KAFKA_CONSUMER_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      URL_ONLINEID_2_PPN: ${BESTPPNAPI_URL_ONLINEID_2_PPN}
      URL_PRINTID_2_PPN: ${BESTPPNAPI_URL_PRINTID_2_PPN}
      URL_DAT_2_PPN: ${BESTPPNAPI_URL_DAT_2_PPN}
      URL_DOI_2_PPN: ${BESTPPNAPI_URL_DOI_2_PPN}
      MAIL_WS_URL: ${MAIL_WS_URL}
      MAIL_WS_RECIPIENT: ${MAIL_WS_RECIPIENT}
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=kbart2kafka"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=java-spring"
      # pour que les mises à jour de cette image soient auto-déployées par watchtower
      - "com.centurylinklabs.watchtower.scope=convergence-bacon-watchtower-scope"

  kafka2sudoc:
    image: abesesr/convergence:${KAFKA2SUDOC_VERSION}
    container_name: kafka2sudoc
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    command: tail -F /dev/null
    environment:
      # Pour basculer sur bon application-xxx.properties préalablement embarqué
      # dans le code ici:
      # https://github.com/abes-esr/abes-hello-back/tree/develop/web/src/main/resources/
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE}
      # Pour surcharger les paramètres spring du application-xxx.properties
      # ci-dessous via le système de .env de docker
      # https://www.linkedin.com/pulse/externalizing-properties-spring-boot-application-docker-phani-bushan
      # pour la liste de tous les champs qu'on peut surcharger,
      # voir le contenu des application-xxx.properties embarqués dans le code sources
      SPRING_KAFKA_CONSUMER_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      SUDOC_SERVEUR: ${KAFKA2SUDOC_SUDOC_SERVEUR}
      SUDOC_PORT: ${KAFKA2SUDOC_SUDOC_PORT}
      SUDOC_PASSWORD: ${KAFKA2SUDOC_SUDOC_PASSWORD}
      SUDOC_LOGIN: ${KAFKA2SUDOC_SUDOC_LOGIN}
      MAIL_WS_URL: ${MAIL_WS_URL}
      MAIL_WS_RECIPIENT: ${MAIL_WS_RECIPIENT}
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=kbart2kafka"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=java-spring"
      # pour que les mises à jour de cette image soient auto-déployées par watchtower
      - "com.centurylinklabs.watchtower.scope=convergence-bacon-watchtower-scope"

  ############################
  # logskbart-api
  # API de logskbart-api
  # (écrite en java spring boot)
  logskbart-api:
    image: abesesr/convergence:${LOGSKBART_API_VERSION}
    container_name: logskbart-api
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    volumes:
      - ${LOGSKBART_API_PATH_TSVFILE}:/tmp/
    environment:
      # Pour basculer sur bon application-xxx.properties préalablement embarqué
      # dans le code ici:
      # https://github.com/abes-esr/abes-hello-back/tree/develop/web/src/main/resources/
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE}
      # Pour surcharger les paramètres spring du application-xxx.properties
      # ci-dessous via le système de .env de docker
      # https://www.linkedin.com/pulse/externalizing-properties-spring-boot-application-docker-phani-bushan
      # pour la liste de tous les champs qu'on peut surcharger,
      # voir le contenu des application-xxx.properties embarqués dans le code sources
      SPRING_KAFKA_CONSUMER_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      SPRING_DATASOURCE_LOGSDB_JDBCURL: 'jdbc:postgresql://logskbart-db:5432/logskbart'
      SPRING_DATASOURCE_LOGSDB_USERNAME: ${LOGSKBART_DB_POSTGRES_USER}
      SPRING_DATASOURCE_LOGSDB_PASSWORD: ${LOGSKBART_DB_POSTGRES_PASSWORD}
      SPRING_DATASOURCE_BACON_JDBCURL: ${LOGSKBART_BACON_JDBCURL}
      SPRING_DATASOURCE_BACON_USERNAME: ${LOGSKBART_BACON_USERNAME}
      SPRING_DATASOURCE_BACON_PASSWORD: ${LOGSKBART_BACON_PASSWORD}
      LOADERTYPE: ${LOGSKBART_API_LOADERTYPE}
    ports:
      - ${LOGSKBART_API_HTTP_PORT}:8082
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=logskbart"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=java-spring"
      # pour que les mises à jour de cette image soient auto-déployées par watchtower
      - "com.centurylinklabs.watchtower.scope=convergence-bacon-watchtower-scope"

  ##############################
  # logskbart-db
  # Base de données postgresql de logskbart
  logskbart-db:
    image: abesesr/postgres-fr_fr:15.1.0
    container_name: logskbart-db
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    environment:
      # cf https://github.com/docker-library/docs/blob/master/postgres/README.md#environment-variables
      POSTGRES_DB: "logskbart"
      POSTGRES_USER: ${LOGSKBART_DB_POSTGRES_USER}
      POSTGRES_PASSWORD: ${LOGSKBART_DB_POSTGRES_PASSWORD}

    volumes:
      - ./volumes/logskbart-db/pgdata/:/var/lib/postgresql/data/
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=convergence"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=postgresql"



  #################################
  # logskbart-db-adminer
  # Interface d'admin de postgresql
  logskbart-db-adminer:
    image: adminer:4.8.1
    container_name: logskbart-db-adminer
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    ports:
      - ${LOGSKBART_DB_ADMINER_HTTP_PORT}:8080
    depends_on:
      - logskbart-db
    environment:
      ADMINER_DEFAULT_SERVER: "logskbart-db"
    logging:
      driver: none # pas de log pour adminer pour ne pas polluer



  #######################################
  # logskbart-db-dumper
  # Dump de la base de données postgresql
  # (dump tous les jours pour les sauvegardes)
  # https://github.com/tiredofit/docker-db-backup
  logskbart-db-dumper:
    image: tiredofit/db-backup:3.3.11
    container_name: logskbart-db-dumper
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    volumes:
      - ./volumes/logskbart-db/dump/:/backup/
    depends_on:
      - logskbart-db
    environment:
      # DB_DUMP_BEGIN: "0130" <= tous les jours à 1h30 du matin GMT
      # DB_DUMP_FREQ: 1440 <= chaque jour
      # DB_CLEANUP_TIME: 10080 (1440*7) <= conserve uniquement les 7 derniers jours
      DB_TYPE: "pgsql"
      DB_HOST: "logskbart-db"
      DB_NAME: "logskbart"
      DB_USER: ${LOGSKBART_DB_POSTGRES_USER}
      DB_PASS: ${LOGSKBART_DB_POSTGRES_PASSWORD}
      DB_DUMP_BEGIN: "0130"
      DB_DUMP_FREQ: 1440
      DB_CLEANUP_TIME: 10080
      SPLIT_DB: "true"
      COMPRESSION: "GZ"
      DEBUG_MODE: "false"
      CONTAINER_ENABLE_SCHEDULING: "false"
      CONTAINER_ENABLE_MONITORING: "false"
    labels:
      - "co.elastic.logs/enabled=true"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=logskbart"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=adhoc"
      # log multiline aussi pour ce conteneur avec des lignes qui ressemblent à ceci:
      # 2022-08-01.14:55:00 [NOTICE] ** [db-backup] Dumping PostgresSQL database: 'logskbart' and compressing with 'gzip'
      - "co.elastic.logs/multiline.type=pattern"
      - "co.elastic.logs/multiline.pattern='^.*Dumping PostgresSQL database'"
      - "co.elastic.logs/multiline.negate=true"
      - "co.elastic.logs/multiline.match=after"

  #######################################
  # convergence-bacon-watchtower
  # Conteneur chargé de mettre à jour automatiquement toutes les N secondes
  # les images docker des conteneurs surveillés (via le système de label/scope de watchtower)
  convergence-bacon-watchtower:
    image: containrrr/watchtower:1.4.0
    container_name: convergence-bacon-watchtower
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      WATCHTOWER_CLEANUP: "true"
      WATCHTOWER_POLL_INTERVAL: 60
      WATCHTOWER_DEBUG: "false"
      WATCHTOWER_NO_STARTUP_MESSAGE: "true"
      WATCHTOWER_WARN_ON_HEAD_FAILURE: "never"
      WATCHTOWER_RUN_ONCE: ${WATCHTOWER_RUN_ONCE}
      WATCHTOWER_NOTIFICATIONS: "slack"
      WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL: ${WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL}
      WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER: ${WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER}
      WATCHTOWER_NOTIFICATION_SLACK_CHANNEL: "#notif-convergence"
      WATCHTOWER_SCOPE: "convergence-bacon-watchtower-scope"
    labels:
      - "com.centurylinklabs.watchtower.scope=convergence-bacon-watchtower-scope"
