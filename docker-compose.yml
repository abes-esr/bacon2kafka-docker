#
# Ci-dessous la config qui permet de lancer convergence-bacon-docker
#
# Remarque: avant de lancer docker-compose up, il faut régler le fichier .env
# en partant du fichier .env-dist qui donne les variables d'environnements
# à personnaliser et des exemples de valeurs.
#

version: "3.7"
services:
  ############################
  # kbart2kafka
  # (écrite en java spring boot)
  kbart2kafka:
    image: abesesr/convergence:${KBART2KAFKA_VERSION}
    container_name: kbart2kafka
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    volumes:
      - ${LOGSKBART_API_PATH_TSVFILE}:/app/kbart/
    environment:
      # Pour basculer sur bon application-xxx.properties préalablement embarqué
      # dans le code ici:
      # https://github.com/abes-esr/abes-hello-back/tree/develop/web/src/main/resources/
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE}
      # Pour surcharger les paramètres spring du application-xxx.properties
      # ci-dessous via le système de .env de docker
      # https://www.linkedin.com/pulse/externalizing-properties-spring-boot-application-docker-phani-bushan
      # pour la liste de tous les champs qu'on peut surcharger,
      # voir le contenu des application-xxx.properties embarqués dans le code sources
      ABES_KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      ABES_KAFKA_CONCURRENCY_NBTHREAD: ${KAFKA_CONCURRENCY_NBTHREAD}
      SPRING_DATASOURCE_BACON_JDBCURL: ${BACON_JDBCURL}
      SPRING_DATASOURCE_BACON_USERNAME: ${BACON_USERNAME}
      SPRING_DATASOURCE_BACON_PASSWORD: ${BACON_PASSWORD}
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=${LOG_ELASTIC_ENABLED}"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=kbart2kafka"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=java-spring"
      # pour que les mises à jour de cette image soient auto-déployées par watchtower
      - "com.centurylinklabs.watchtower.scope=convergence-bacon-watchtower-scope"

  #########################################
  # best-ppn-api
  # API en spring
  best-ppn-api:
    image: abesesr/convergence:${BESTPPNAPI_VERSION}
    container_name: best-ppn-api
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    volumes:
      - ${LOGSKBART_API_PATH_TSVFILE}:/app/tempLog/
    ports:
      - ${BESTPPNAPI_PORT}:8083
    environment:
      # Pour basculer sur bon application-xxx.properties préalablement embarqué
      # dans le code ici:
      # https://github.com/abes-esr/abes-hello-back/tree/develop/web/src/main/resources/
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE}
      # Pour surcharger les paramètres spring du application-xxx.properties
      # ci-dessous via le système de .env de docker
      # https://www.linkedin.com/pulse/externalizing-properties-spring-boot-application-docker-phani-bushan
      # pour la liste de tous les champs qu'on peut surcharger,
      # voir le contenu des application-xxx.properties embarqués dans le code sources
      ABES_KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      ABES_KAFKA_REGISTRY_URL: ${KAFKA_REGISTRY_URL}
      ABES_KAFKA_CONCURRENCY_NBTHREAD: ${KAFKA_CONCURRENCY_NBTHREAD}
      SPRING_DATASOURCE_BASEXML_JDBCURL: ${BESTPPNAPI_SPRING_DATASOURCE_BASEXML_JDBCURL}
      SPRING_DATASOURCE_BASEXML_USERNAME: ${BESTPPNAPI_SPRING_DATASOURCE_BASEXML_USERNAME}
      SPRING_DATASOURCE_BASEXML_PASSWORD: ${BESTPPNAPI_SPRING_DATASOURCE_BASEXML_PASSWORD}
      SPRING_DATASOURCE_BACON_JDBCURL: ${BACON_JDBCURL}
      SPRING_DATASOURCE_BACON_USERNAME: ${BACON_USERNAME}
      SPRING_DATASOURCE_BACON_PASSWORD: ${BACON_PASSWORD}
      URL_ONLINEID2PPN: ${BESTPPNAPI_URL_ONLINEID_2_PPN}
      URL_PRINTID2PPN: ${BESTPPNAPI_URL_PRINTID_2_PPN}
      URL_DAT2PPN: ${BESTPPNAPI_URL_DAT_2_PPN}
      URL_DOI2PPN: ${BESTPPNAPI_URL_DOI_2_PPN}
      MAIL_WS_URL: ${MAIL_WS_URL}
      MAIL_WS_RECIPIENT: ${MAIL_WS_RECIPIENT}
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=${LOG_ELASTIC_ENABLED}"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=best-ppn-api"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=java-spring"
      # pour que les mises à jour de cette image soient auto-déployées par watchtower
      - "com.centurylinklabs.watchtower.scope=convergence-bacon-watchtower-scope"

  #########################################
  # kafka2sudoc
  # (écrite en java spring boot)
  kafka2sudoc:
    image: abesesr/convergence:${KAFKA2SUDOC_VERSION}
    container_name: kafka2sudoc
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    command: tail -F /dev/null
    environment:
      # Pour basculer sur bon application-xxx.properties préalablement embarqué
      # dans le code ici:
      # https://github.com/abes-esr/abes-hello-back/tree/develop/web/src/main/resources/
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE}
      # Pour surcharger les paramètres spring du application-xxx.properties
      # ci-dessous via le système de .env de docker
      # https://www.linkedin.com/pulse/externalizing-properties-spring-boot-application-docker-phani-bushan
      # pour la liste de tous les champs qu'on peut surcharger,
      # voir le contenu des application-xxx.properties embarqués dans le code sources
      ABES_KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      ABES_KAFKA_REGISTRY_URL: ${KAFKA_REGISTRY_URL}
      ABES_KAFKA_CONCURRENCY_NBTHREAD: ${KAFKA_CONCURRENCY_NBTHREAD}
      SUDOC_SERVEUR: ${KAFKA2SUDOC_SUDOC_SERVEUR}
      SUDOC_PORT: ${KAFKA2SUDOC_SUDOC_PORT}
      SUDOC_PASSWORD: ${KAFKA2SUDOC_SUDOC_PASSWORD}
      SUDOC_LOGIN: ${KAFKA2SUDOC_SUDOC_LOGIN}
      SUDOC_SIGNALDB: ${KAFKA2SUDOC_SUDOC_SIGNALDB}
      SPRING_DATASOURCE_BACON_JDBCURL: ${BACON_JDBCURL}
      SPRING_DATASOURCE_BACON_USERNAME: ${BACON_USERNAME}
      SPRING_DATASOURCE_BACON_PASSWORD: ${BACON_PASSWORD}
      MAIL_WS_URL: ${MAIL_WS_URL}
      MAIL_WS_RECIPIENT: ${MAIL_WS_RECIPIENT}
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=${LOG_ELASTIC_ENABLED}"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=kafka2sudoc"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=java-spring"
      # pour que les mises à jour de cette image soient auto-déployées par watchtower
      - "com.centurylinklabs.watchtower.scope=convergence-bacon-watchtower-scope"

  #########################################
  # bacon-provider-api
  # API en spring
  bacon-provider-api:
    image: abesesr/convergence:${BACON_PROVIDER_API_VERSION}
    container_name: bacon-provider-api
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    environment:
      # Pour basculer sur bon application-xxx.properties préalablement embarqué
      # dans le code ici:
      # https://github.com/abes-esr/abes-hello-back/tree/develop/web/src/main/resources/
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE}
      # Pour surcharger les paramètres spring du application-xxx.properties
      # ci-dessous via le système de .env de docker
      # https://www.linkedin.com/pulse/externalizing-properties-spring-boot-application-docker-phani-bushan
      # pour la liste de tous les champs qu'on peut surcharger,
      # voir le contenu des application-xxx.properties embarqués dans le code sources
      SPRING_DATASOURCE_BACON_JDBCURL: ${BACON_JDBCURL}
      SPRING_DATASOURCE_BACON_USERNAME: ${BACON_USERNAME}
      SPRING_DATASOURCE_BACON_PASSWORD: ${BACON_PASSWORD}
    ports:
      - ${BACON_PROVIDER_API_HTTP_PORT}:8084
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=${LOG_ELASTIC_ENABLED}"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=logskbart-api"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=java-spring"
      # pour que les mises à jour de cette image soient auto-déployées par watchtower
      - "com.centurylinklabs.watchtower.scope=convergence-bacon-watchtower-scope"

  ############################
  # logskbart-api
  # API de logskbart-api
  # (écrite en java spring boot)
  logskbart-api:
    image: abesesr/convergence:${LOGSKBART_API_VERSION}
    container_name: logskbart-api
    depends_on:
      logskbart-elasticsearch:
        condition: service_healthy
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    volumes:
      - ${LOGSKBART_API_PATH_TSVFILE}:/app/tempLog/
    environment:
      # Pour basculer sur bon application-xxx.properties préalablement embarqué
      # dans le code ici:
      # https://github.com/abes-esr/abes-hello-back/tree/develop/web/src/main/resources/
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE}
      # Pour surcharger les paramètres spring du application-xxx.properties
      # ci-dessous via le système de .env de docker
      # https://www.linkedin.com/pulse/externalizing-properties-spring-boot-application-docker-phani-bushan
      # pour la liste de tous les champs qu'on peut surcharger,
      # voir le contenu des application-xxx.properties embarqués dans le code sources
      ABES_KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      SPRING_ELASTICSEARCH_URIS: http://logskbart-elasticsearch:9200
      ABES_KAFKA_CONCURRENCY_NBTHREAD: ${KAFKA_CONCURRENCY_NBTHREAD}
      MAIL_WS_URL: ${MAIL_WS_URL}
      MAIL_WS_RECIPIENT: ${MAIL_WS_RECIPIENT}
    ports:
      - ${LOGSKBART_API_HTTP_PORT}:8082
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=${LOG_ELASTIC_ENABLED}"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=logskbart-api"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=java-spring"
      # pour que les mises à jour de cette image soient auto-déployées par watchtower
      - "com.centurylinklabs.watchtower.scope=convergence-bacon-watchtower-scope"



  #######################################
  # logskbart-elasticsearch
  # Ref. https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
  logskbart-elasticsearch:
    container_name: logskbart-elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.3
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    memswap_limit: ${MEM_LIMIT}
    cpus: ${CPU_LIMIT}
    ports:
      # réglage explicites des ports internes et externes pour pouvoir fonctionner en cluster
      # cf https://blog.cri.epita.fr/post/2019-06-10-elasticsearch-cluster-formation-issue/
      - "9200:9200"
    environment:
      - discovery.type=single-node
      # pour désactiver les recherches complexe (conseillé par https://checkups.opster.com/checkup/result/75470)
      # "Recommendations : Allow expensive queries can be disabled by setting config search.allow_expensive_queries: false in the yaml config file and then restarting the node."
      - search.allow_expensive_queries=true
      # pour la quantité de données mises en cache
      # https://www.elastic.co/guide/en/elasticsearch/reference/current/shard-request-cache.html#_cache_settings
      - indices.requests.cache.size=10%
      # réglage pour désactiver le swap: https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#_disable_swapping
      - bootstrap.memory_lock=true
      # pour éviter que les dump geoip soient téléchargés régulièrement dans /tmp/
      # cf https://abes-esr.atlassian.net/browse/THE-188
      # cf https://www.elastic.co/guide/en/elasticsearch/reference/current/geoip-processor.html#geoip-cluster-settings
      # cf https://www.elastic.co/guide/en/elasticsearch/reference/current/executable-jna-tmpdir.html
      - ingest.geoip.downloader.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
      # licence à utiliser (basic ou trial pour un essai de 30 jours)
      - xpack.license.self_generated.type=basic
      # pour avoir plus ou moins de logs elasticsearch
      # DEBUG ou INFO (en prod mettre INFO)
      - logger.org.elasticsearch.discovery=INFO
      - http.max_content_length=500mb
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s 'http://logskbart-elasticsearch:9200/_cluster/health?timeout=5s&pretty=true' | grep status | grep -E -q 'yellow|green'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=${LOG_ELASTIC_ENABLED}"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=logskbart-elasticsearch"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=elasticsearch"



  #######################################
  # logskbart-kibana
  # kibana est le frontoffice de l'elasticsearch de logskbart
  logskbart-kibana:
    container_name: logskbart-kibana
    depends_on:
      - logskbart-elasticsearch
    image: docker.elastic.co/kibana/kibana:8.10.3
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    memswap_limit: ${MEM_LIMIT}
    cpus: ${CPU_LIMIT}
    environment:
      ELASTICSEARCH_HOSTS: http://logskbart-elasticsearch:9200
    ports:
      - "5601:5601"
    labels:
      # pour envoyer les logs dans le puits de log de l'abes
      - "co.elastic.logs/enabled=${LOG_ELASTIC_ENABLED}"
      - "co.elastic.logs/processors.add_fields.target="
      - "co.elastic.logs/processors.add_fields.fields.abes_appli=logskbart-kibana"
      - "co.elastic.logs/processors.add_fields.fields.abes_middleware=kibana"

  #######################################
  # convergence-bacon-watchtower
  # Conteneur chargé de mettre à jour automatiquement toutes les N secondes
  # les images docker des conteneurs surveillés (via le système de label/scope de watchtower)
  convergence-bacon-watchtower:
    image: containrrr/watchtower:1.4.0
    container_name: convergence-bacon-watchtower
    restart: unless-stopped
    mem_limit: ${MEM_LIMIT}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      WATCHTOWER_CLEANUP: "true"
      WATCHTOWER_POLL_INTERVAL: 60
      WATCHTOWER_DEBUG: "false"
      WATCHTOWER_NO_STARTUP_MESSAGE: "true"
      WATCHTOWER_WARN_ON_HEAD_FAILURE: "never"
      WATCHTOWER_RUN_ONCE: ${WATCHTOWER_RUN_ONCE}
      WATCHTOWER_NOTIFICATIONS: "slack"
      WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL: ${WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL}
      WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER: ${WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER}
      WATCHTOWER_NOTIFICATION_SLACK_CHANNEL: "#notif-convergence"
      WATCHTOWER_SCOPE: "convergence-bacon-watchtower-scope"
      REPO_USER: ${WATCHTOWER_DOCKERHUB_USER}
      REPO_PASS: ${WATCHTOWER_DOCKERHUB_PASS}
    labels:
      - "com.centurylinklabs.watchtower.scope=convergence-bacon-watchtower-scope"
